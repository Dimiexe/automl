{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import arff\n",
    "import re\n",
    "import codecs\n",
    "path_to_dataset_folder = '..\\\\DATAsets\\\\DATA'\n",
    "path_to_ready_csv = path_to_dataset_folder + '\\\\CSVs'\n",
    "path_encoded_csv = path_to_dataset_folder + '\\\\CSVs_reverse_encoded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timedelta', 'n_tokens_title', 'n_tokens_content', 'n_unique_tokens',\n",
       "       'n_non_stop_words', 'n_non_stop_unique_tokens', 'num_hrefs',\n",
       "       'num_self_hrefs', 'num_imgs', 'num_videos', 'average_token_length',\n",
       "       'num_keywords', 'kw_min_min', 'kw_max_min', 'kw_avg_min', 'kw_min_max',\n",
       "       'kw_avg_max', 'kw_min_avg', 'kw_max_avg', 'kw_avg_avg',\n",
       "       'self_reference_min_shares', 'self_reference_max_shares',\n",
       "       'self_reference_avg_sharess', 'is_weekend', 'LDA_00', 'LDA_01',\n",
       "       'LDA_02', 'LDA_03', 'LDA_04', 'global_subjectivity',\n",
       "       'global_sentiment_polarity', 'global_rate_positive_words',\n",
       "       'global_rate_negative_words', 'rate_positive_words',\n",
       "       'rate_negative_words', 'avg_positive_polarity', 'min_positive_polarity',\n",
       "       'max_positive_polarity', 'avg_negative_polarity',\n",
       "       'min_negative_polarity', 'max_negative_polarity', 'title_subjectivity',\n",
       "       'title_sentiment_polarity', 'abs_title_subjectivity',\n",
       "       'abs_title_sentiment_polarity', 'shares', 'Weekday', 'type_of_channel',\n",
       "       'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path_to_dataset_folder + '/Target_feature_test_CSVs/OnlineNewsPopularity%kw_max_max.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_channel_is_lifestyle</th>\n",
       "      <th>data_channel_is_entertainment</th>\n",
       "      <th>data_channel_is_bus</th>\n",
       "      <th>data_channel_is_socmed</th>\n",
       "      <th>data_channel_is_tech</th>\n",
       "      <th>data_channel_is_world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     data_channel_is_lifestyle  data_channel_is_entertainment  \\\n",
       "120                        0.0                            1.0   \n",
       "121                        0.0                            0.0   \n",
       "122                        0.0                            0.0   \n",
       "123                        0.0                            0.0   \n",
       "124                        0.0                            0.0   \n",
       "125                        0.0                            0.0   \n",
       "126                        0.0                            1.0   \n",
       "127                        0.0                            0.0   \n",
       "\n",
       "     data_channel_is_bus  data_channel_is_socmed  data_channel_is_tech  \\\n",
       "120                  0.0                     0.0                   0.0   \n",
       "121                  0.0                     0.0                   1.0   \n",
       "122                  0.0                     0.0                   1.0   \n",
       "123                  0.0                     0.0                   0.0   \n",
       "124                  0.0                     0.0                   0.0   \n",
       "125                  0.0                     1.0                   0.0   \n",
       "126                  0.0                     0.0                   0.0   \n",
       "127                  0.0                     0.0                   0.0   \n",
       "\n",
       "     data_channel_is_world  \n",
       "120                    0.0  \n",
       "121                    0.0  \n",
       "122                    0.0  \n",
       "123                    1.0  \n",
       "124                    1.0  \n",
       "125                    0.0  \n",
       "126                    0.0  \n",
       "127                    0.0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"OnlineNewsPopularity.csv\"\n",
    "df = pd.read_table(path_to_ready_csv + '\\\\'+ file,sep=',')\n",
    "df.iloc[120:128,12:18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = df.dtypes\n",
    "cardi = df.apply(pd.Series.nunique)\n",
    "df2=pd.DataFrame({'Types': types,\n",
    "                  'Cardinality': cardi})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_channel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>socmed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>entertainment</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>lifestyle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type_of_channel\n",
       "120   entertainment\n",
       "121            tech\n",
       "122            tech\n",
       "123           world\n",
       "124           world\n",
       "125          socmed\n",
       "126   entertainment\n",
       "128       lifestyle"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[107:115,df.shape[1]-1:df.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#This is used to turn int-encoded features into str-encoded ones. This is desired\n",
    "#because the str type is automatically recognised as categorical (enum) by H2O later.\n",
    "#Set the variable 'features' to contain the int-encoded features to transform.\n",
    "features = [\"target_class\"]\n",
    "for target_feature in features:\n",
    "    value_df = df[target_feature].value_counts(dropna=True).rename_axis('unique_values',axis=0).reset_index(name='value_counts',drop=False)\n",
    "    value_df.sort_values(by='unique_values',inplace=True)\n",
    "    value_df.reset_index(drop=True,inplace=True)\n",
    "    lim = value_df.shape[0]\n",
    "    replace_dict = {}\n",
    "    for i in range(lim):\n",
    "        replace_dict[ value_df.loc[i,'unique_values'] ] = 'Level_'+str(i)\n",
    "    replace_dict = {target_feature : replace_dict}\n",
    "\n",
    "    df.replace(to_replace = replace_dict, inplace=True, value=None)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   timedelta  n_tokens_title  n_tokens_content  n_unique_tokens  \\\n",
      "0      731.0            12.0             219.0         0.663594   \n",
      "1      731.0             9.0             255.0         0.604743   \n",
      "2      731.0             9.0             211.0         0.575130   \n",
      "3      731.0             9.0             531.0         0.503788   \n",
      "4      731.0            13.0            1072.0         0.415646   \n",
      "5      731.0            10.0             370.0         0.559889   \n",
      "6      731.0             8.0             960.0         0.418163   \n",
      "7      731.0            12.0             989.0         0.433574   \n",
      "8      731.0            11.0              97.0         0.670103   \n",
      "9      731.0            10.0             231.0         0.636364   \n",
      "\n",
      "   n_non_stop_words  n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  \\\n",
      "0               1.0                  0.815385        4.0             2.0   \n",
      "1               1.0                  0.791946        3.0             1.0   \n",
      "2               1.0                  0.663866        3.0             1.0   \n",
      "3               1.0                  0.665635        9.0             0.0   \n",
      "4               1.0                  0.540890       19.0            19.0   \n",
      "5               1.0                  0.698198        2.0             2.0   \n",
      "6               1.0                  0.549834       21.0            20.0   \n",
      "7               1.0                  0.572108       20.0            20.0   \n",
      "8               1.0                  0.836735        2.0             0.0   \n",
      "9               1.0                  0.797101        4.0             1.0   \n",
      "\n",
      "   num_imgs  num_videos  ...  max_positive_polarity  avg_negative_polarity  \\\n",
      "0       1.0         0.0  ...                    0.7              -0.350000   \n",
      "1       1.0         0.0  ...                    0.7              -0.118750   \n",
      "2       1.0         0.0  ...                    1.0              -0.466667   \n",
      "3       1.0         0.0  ...                    0.8              -0.369697   \n",
      "4      20.0         0.0  ...                    1.0              -0.220192   \n",
      "5       0.0         0.0  ...                    0.6              -0.195000   \n",
      "6      20.0         0.0  ...                    1.0              -0.224479   \n",
      "7      20.0         0.0  ...                    1.0              -0.242778   \n",
      "8       0.0         0.0  ...                    0.8              -0.125000   \n",
      "9       1.0         1.0  ...                    0.5              -0.238095   \n",
      "\n",
      "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
      "0                 -0.600              -0.200000            0.500000   \n",
      "1                 -0.125              -0.100000            0.000000   \n",
      "2                 -0.800              -0.133333            0.000000   \n",
      "3                 -0.600              -0.166667            0.000000   \n",
      "4                 -0.500              -0.050000            0.454545   \n",
      "5                 -0.400              -0.100000            0.642857   \n",
      "6                 -0.500              -0.050000            0.000000   \n",
      "7                 -0.500              -0.050000            1.000000   \n",
      "8                 -0.125              -0.125000            0.125000   \n",
      "9                 -0.500              -0.100000            0.000000   \n",
      "\n",
      "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
      "0                 -0.187500                0.000000   \n",
      "1                  0.000000                0.500000   \n",
      "2                  0.000000                0.500000   \n",
      "3                  0.000000                0.500000   \n",
      "4                  0.136364                0.045455   \n",
      "5                  0.214286                0.142857   \n",
      "6                  0.000000                0.500000   \n",
      "7                  0.500000                0.500000   \n",
      "8                  0.000000                0.375000   \n",
      "9                  0.000000                0.500000   \n",
      "\n",
      "   abs_title_sentiment_polarity  shares  type_of_channel  \n",
      "0                      0.187500   593.0    entertainment  \n",
      "1                      0.000000   711.0              bus  \n",
      "2                      0.000000  1500.0              bus  \n",
      "3                      0.000000  1200.0    entertainment  \n",
      "4                      0.136364   505.0             tech  \n",
      "5                      0.214286   855.0             tech  \n",
      "6                      0.000000   556.0        lifestyle  \n",
      "7                      0.500000   891.0             tech  \n",
      "8                      0.000000  3600.0             tech  \n",
      "9                      0.000000   710.0            world  \n",
      "\n",
      "[10 rows x 55 columns]\n"
     ]
    }
   ],
   "source": [
    "#Used to REVERSE ONE HOT ENCODING of the \"invOneHotFeatures\" CONSECUTIVE-features' vector,\n",
    "#creating a new column with the name given in ~~~HERE_1~~~. A check is made if every feature\n",
    "#belongs to exactly one category. If not, this is not usable, and that case needs to be dealt\n",
    "#with manually. The values of the new column can be default (categoricals) if \"autoValues\" == 1,\n",
    "#or manually defined IN THE CODE (~~~HERE_2~~~) for autoValues == 0.\n",
    "\n",
    "invOneHotFeatures = list(range(12,18)) #Consecutive feature indices\n",
    "#invOneHotFeatures = [2,8,12] #Separate features indices\n",
    "autoValues = 0\n",
    "df2=df.iloc[:,invOneHotFeatures]\n",
    "ser = df2.sum(axis=1)\n",
    "if len(ser[ser != 0]) == df.shape[0]:\n",
    "    if ser[ser!=1].sum() == 0:\n",
    "        reverse_enc = []\n",
    "        for x in range(df.shape[0]):\n",
    "            for feat in invOneHotFeatures:\n",
    "                if df.iloc[x,feat] == 1:\n",
    "                    if autoValues == 0:\n",
    "                        #~~~HERE_2~~~\n",
    "                        #Manual definition of values in the new column.\n",
    "                        reverse_enc.append(df.columns.values[feat].split('_')[-1])\n",
    "                    elif autoValues == 1:\n",
    "                        #Automated value assignement as \"value_0, value_1\" etc.\n",
    "                        reverse_enc.append('value_'+str(feat-min(invOneHotFeatures)))\n",
    "                    break\n",
    "        #~~~HERE_1~~~\n",
    "        df=df.assign(type_of_channel=reverse_enc)\n",
    "        df.drop(df.columns.values[invOneHotFeatures],axis=1,inplace=True)\n",
    "        print(df.head(10))\n",
    "    else:\n",
    "        print('Not all features belong exclusively to one category!')\n",
    "else:\n",
    "    print(str(len(ser[ser == 0])) + ' out of '+ str(df.shape[0]) +' features ('+ str(round(len(ser[ser == 0])/df.shape[0]*10000)/100) +'%) belong to NO category!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to drop problematic rows detected above.\n",
    "df2=df.iloc[:,invOneHotFeatures]\n",
    "ser = df2.sum(axis=1)\n",
    "df.drop(ser[ser == 0].index,axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_encoded_csv + '\\\\'+ file,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
