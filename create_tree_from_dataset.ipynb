{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.tree as tr\n",
    "from sklearn import preprocessing\n",
    "path_to_dataset_folder = '../DATAsets'\n",
    "target_test_path = path_to_dataset_folder + '/DATA/Target_feature_test_CSVs'\n",
    "tree_meta_feature_path = path_to_dataset_folder + '/DATA/tree_metafeatures_for_test_CSVs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to make a dictionary with leave nodes' ids maped to their branch lengths. So there are that many key:value\n",
    "#entries as the numbeer of leaves. The aformentioned dictionary is the global variable \"branch_lengths\".\n",
    "branch_lengths = {}\n",
    "def get_branches_len(input_tree_, start_node, counter):\n",
    "    if input_tree_.children_left[start_node] !=-1:\n",
    "        counter += 1\n",
    "        get_branches_len(input_tree_,input_tree_.children_left[start_node],counter)\n",
    "        get_branches_len(input_tree_,input_tree_.children_right[start_node],counter)\n",
    "    else:\n",
    "        global branch_lengths\n",
    "        branch_lengths[start_node] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a list of ints, containing the node ids of the leaves.\n",
    "def find_leaves(input_tree_):\n",
    "    leaves = []\n",
    "    for node in range(input_tree_.node_count):\n",
    "        if input_tree_.children_left[node] == -1:\n",
    "            leaves.append(node)\n",
    "    return leaves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dictionary with level-id int keys maped to the nodes on that level. e.g. 0:0, 1:[1,2] for a simple 2-level tree\n",
    "#root + 2 children nodes.\n",
    "def get_levels(input_tree_):\n",
    "    levels = {0:[0]}\n",
    "    for i in range(input_tree_.max_depth):\n",
    "        left_children = [input_tree_.children_left[x] for x in levels[i] if input_tree_.children_left[x] != -1]\n",
    "        right_children = [input_tree_.children_right[x] for x in levels[i] if input_tree_.children_right[x] != -1]\n",
    "        levels[i+1] = left_children + right_children\n",
    "    return levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a dictionary with the features as keys, and their frequency of appearance as values.\n",
    "def get_feature_freq(input_tree_):\n",
    "    freqs = {}\n",
    "    for i in range(input_tree_.node_count):\n",
    "        if input_tree_.children_left[i] !=-1:\n",
    "            if input_tree_.feature[i] in freqs:\n",
    "                freqs[input_tree_.feature[i]] +=1\n",
    "            else:\n",
    "                freqs[input_tree_.feature[i]] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The below code was found at: https://www.geeksforgeeks.org/diameter-of-a-binary-tree-in-on-a-new-method/\n",
    "#and tweaked slightly to match the needs of this work.\n",
    "\n",
    "# Function to find height of a tree  \n",
    "def height(tree_,root, ans): \n",
    "    if (root == -1): \n",
    "        return 0\n",
    "  \n",
    "    left_height = height(tree_,tree_.children_left[root], ans)  \n",
    "  \n",
    "    right_height = height(tree_,tree_.children_right[root], ans)  \n",
    "  \n",
    "    # update the answer, because diameter  \n",
    "    # of a tree is nothing but maximum  \n",
    "    # value of (left_height + right_height + 1) \n",
    "    # for each node  \n",
    "    ans[0] = max(ans[0], 1 + left_height + \n",
    "                             right_height)  \n",
    "  \n",
    "    return 1 + max(left_height, \n",
    "                   right_height) \n",
    "  \n",
    "# Computes the diameter of binary  \n",
    "# tree with given root.  \n",
    "def diameter(tree_,root): \n",
    "    if (root < 0):  \n",
    "        return 0\n",
    "    ans = [-999999999999] # This will store \n",
    "                          # the final answer  \n",
    "    height_of_tree = height(tree_,root, ans)  \n",
    "    return ans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the 14-element feature vector (list) of the given dataFrame (df). Also if \"visual_tree\" is True,\n",
    "#then the tree is ploted, default value: False.\n",
    "def metafeatures(df, visual_tree = False):\n",
    "    meta_vector = []\n",
    "    x = df.loc[:,df.columns[0:-1]]\n",
    "    y = df.loc[:,df.columns[-1]]\n",
    "    regr = tr.DecisionTreeRegressor(random_state = 8328, min_impurity_decrease = 1e-06)\n",
    "    regr.fit(x,y)\n",
    "    if visual_tree:\n",
    "        tr.plot_tree(regr)\n",
    "    \n",
    "    #1 Tree width (diameter)\n",
    "    meta_vector.append(diameter(regr.tree_,0))    \n",
    "    #2 Tree height\n",
    "    meta_vector.append(regr.tree_.max_depth)    \n",
    "    #3 Total number of nodes\n",
    "    meta_vector.append(regr.tree_.node_count)    \n",
    "    #4 Total number of leaves\n",
    "    meta_vector.append(len(find_leaves(regr.tree_)))\n",
    "    \n",
    "    levels = get_levels(regr.tree_)\n",
    "    nodes_per_level = [len(levels[i]) for i in range(len(levels))]    \n",
    "    #5 Maximun nodes per level\n",
    "    meta_vector.append(np.max(nodes_per_level))\n",
    "    #6 Mean number of nodes per level\n",
    "    meta_vector.append(np.mean(nodes_per_level))\n",
    "    #7 Standard deviation of nodes per level\n",
    "    meta_vector.append(np.std(nodes_per_level))\n",
    "    \n",
    "    global branch_lengths\n",
    "    branch_lengths = {} #(re)initialise the global variable to hold the branches and their lengths\n",
    "    get_branches_len(regr.tree_,0,0)\n",
    "    length_per_branch = [branch_lengths[x] for x in branch_lengths]\n",
    "    #(8) Longest branch's length| Not used because it's always the same as #2 Tree height\n",
    "    #meta_vector.append(np.max(length_per_branch))\n",
    "    #8 Shortest branch's length\n",
    "    meta_vector.append(np.min(length_per_branch))\n",
    "    #9 Mean length of branches\n",
    "    meta_vector.append(np.mean(length_per_branch))\n",
    "    #10 Standard deviation of length of branches\n",
    "    meta_vector.append(np.std(length_per_branch))\n",
    "    \n",
    "    feature_frequencies = get_feature_freq(regr.tree_)\n",
    "    freqs = [feature_frequencies[x] for x in feature_frequencies]\n",
    "    #11 Maximum frequency of feature appearance\n",
    "    meta_vector.append(np.max(freqs))\n",
    "    #12 Minimum frequency of feature appearance\n",
    "    meta_vector.append(np.min(freqs))\n",
    "    #13 Mean frequency of feature appearance\n",
    "    meta_vector.append(np.mean(freqs))\n",
    "    #14 Standard deviation of frequency of feature appearance\n",
    "    meta_vector.append(np.std(freqs))\n",
    "    \n",
    "    return meta_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function prepares the dataframe for metafeature extraction. \n",
    "#First a missing values imputation is performed using the \"method\" arguement:\n",
    "# drop = all instances with at least one missing value are droped,\n",
    "# mean = missing values are assigned the mean value for each numerical feature,\n",
    "# median = missing values are assigned the median value for each numerical feature.\n",
    "#In any case, any missing values on categorical deatures are filled with the mode of\n",
    "#each feature, the value most frequently seen.\n",
    "#Returns the processed dataframe and the NaNs per line metric.\n",
    "def tree_ready(df, method = 'drop'):\n",
    "    total_nans = df.isna().sum().sum()\n",
    "    mean_nans_per_line = total_nans / df.shape[0]\n",
    "    feats_to_encode = [feat for i, feat in enumerate(df.columns) if df.dtypes[i] == 'object']\n",
    "    if total_nans > 0:\n",
    "        cols = np.setdiff1d(df.columns, feats_to_encode)\n",
    "        if method == 'drop':\n",
    "            df.dropna(axis = 0, how = 'any', inplace = True)\n",
    "        elif method == 'mean':            \n",
    "            df.fillna({col: df.loc[:,col].mean() for col in cols}, inplace = True)\n",
    "            df.fillna({col: df.loc[:,col].mode()[0] for col in feats_to_encode}, inplace = True)\n",
    "        elif method == 'median':\n",
    "            df.fillna({col: df.loc[:,col].median() for col in cols}, inplace = True)\n",
    "            df.fillna({col: df.loc[:,col].mode()[0] for col in feats_to_encode}, inplace = True)\n",
    "        else:\n",
    "            print('Non identifiable method provided!')\n",
    "            return None, None\n",
    "        \n",
    "    for x in feats_to_encode:\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        df.loc[:,x] = le.fit_transform(df.loc[:,x])\n",
    "    return df , mean_nans_per_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proccessing file: 2014 and 2015 CSM dataset%Screens.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Admission_Predict_Ver1%SOP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: AirQualityUCI%CO(GT).csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: BeijingPM20100101_20151231%TEMP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Bike-Sharing-day%temp.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Bike-Sharing-hour%hum.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Bike-Sharing-hour%windspeed.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: CASP%F9.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: COMBO17%UFS.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: COMBO17%W518FE.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: COMBO17%e.VjMAG.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: COMBO17%e.gsMAG.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ChengduPM20100101_20151231%DEWP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Concrete_Data%Concrete compressive strength.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Daily_Demand_Forecasting_Orders%Fiscal sector orders.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ENB2012_data%X4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Financial Distress%Financial Distress.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Financial Distress%x11.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Financial Distress%x42.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Financial Distress%x49.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Financial Distress%x55.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: GuangzhouPM20100101_20151231%TEMP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: HR_comma_sep%last_evaluation.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Housing_prices%1stFlrSF.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Housing_prices%BsmtFinSF1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Housing_prices%BsmtUnfSF.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Housing_prices%LotArea.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Housing_prices%TotalBsmtSF.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: LasVegasTripAdvisorReviews-Dataset%Helpful votes.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: LasVegasTripAdvisorReviews-Dataset%Score.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Life Expectancy Data% thinness 5-9 years.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Life Expectancy Data%percentage expenditure.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Metro_Interstate_Traffic_Volume%temp.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: NEW-DATA%13-Meteo_Exterior_Crepusculo.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: NEW-DATA%17-Meteo_Exterior_Sol_Sud.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: OnlineNewsPopularity%LDA_02.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: OnlineNewsPopularity%kw_max_max.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: OnlineNewsPopularity%max_positive_polarity.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: OnlineNewsPopularity%min_positive_polarity.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: OnlineNewsPopularity%n_unique_tokens.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: PRSA_data_2010%pm2.5.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Parkinson_Multiple_Sound_Recording%12.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Parkinson_Multiple_Sound_Recording%18.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Parkinson_Multiple_Sound_Recording%26.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Reaction Network (Undirected)%14.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Reaction Network (Undirected)%16.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Reaction Network (Undirected)%25.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Real estate valuation data set%X6 longitude.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Residential-Building-Data-Set%V-11.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Residential-Building-Data-Set%V-12.4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Residential-Building-Data-Set%V-15.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Residential-Building-Data-Set%V-17.4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Residential-Building-Data-Set%V-2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ShanghaiPM20100101_20151231%precipitation.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ShenyangPM20100101_20151231%HUMI.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: SkillCraft1_Dataset%Age.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: SwedishMotorInsurance%Insured.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: Train_AccountInfo%BaseCharges.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: UCI CBM Dataset data%0.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: UCI CBM Dataset data%9.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: YearPredictionMSD1%10.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: YearPredictionMSD2%36.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: YearPredictionMSD3%74.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: YearPredictionMSD4%52.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: YearPredictionMSD5%90.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: acs2015_county_data%Native.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: acs2015_county_data%Pacific.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: acs2015_county_data%Poverty.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: acs2015_county_data%Service.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: airfoil_self_noise%1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: auto-mpg%2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: baboon_mating%female_gendiv.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: baboon_mating%male_gendiv.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: boston-housing-dataset%MEDV.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: breast-cancer-wisconsin-data%area_se.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: breast-cancer-wisconsin-data%fractal_dimension_se.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: breast-cancer-wisconsin-data%symmetry_mean.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: c_bank%palladium.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: c_bank%silver.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: carbon_nanotubes%Calculated atomic coordinates u'.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ccpp%AT.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: cities_r2%effective_literacy_rate_total.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: cities_r2%latitude.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: communities%32.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: communities%37.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: communities%52.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: communities%82.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: communities%84.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: data_akbilgic%BOVESPA.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: dataset_Facebook%Lifetime Engaged Users.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proccessing file: dataset_Facebook%like.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default of credit card clients%BILL_AMT3.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default of credit card clients%BILL_AMT4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default of credit card clients%PAY_AMT4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default_features_1059_tracks%24.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default_features_1059_tracks%46.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default_features_1059_tracks%47.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default_features_1059_tracks%49.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: default_features_1059_tracks%67.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: eb%0.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: energydata_complete%RH_8.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: energydata_complete%T9.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: energydata_complete%rv1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: fertility_Diagnosis%6.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: flare%11.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: forestfires%area.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: go_track_tracks%time.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: googleplaystore%Reviews.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: heart%thalach.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: imports-85%12.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: imports-85%18.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: imports-85%25.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: kc_house_data%price.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: kc_house_data%sqft_lot.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: machine%8.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: online_retail_II1%Price.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: online_retail_II2%hour.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_features_1059_tracks%2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_features_1059_tracks%23.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_features_1059_tracks%38.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_features_1059_tracks%68.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_features_1059_tracks%69.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%116.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%117.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%32.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%58.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%76.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: origin of music default_plus_chromatic_features_1059_tracks%89.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: parkinsons_updrs%Jitter(%).csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: parkinsons_updrs%test_time.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_Boston%wind_direction.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_Houston%humidity.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_Jacksonville%temperature.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_Los Angeles%temperature.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Nongzhanguan_20130301-20170228%NO2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Nongzhanguan_20130301-20170228%PRES.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Tiantan_20130301-20170228%DEWP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Tiantan_20130301-20170228%SO2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Wanshouxigong_20130301-20170228%DEWP.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_PRSA_Data_Wanshouxigong_20130301-20170228%PM2.5.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: processed_Seattle%temperature.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: pulsar_stars% Excess kurtosis of the DM-SNR curve.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: qsar_aquatic_toxicity%8.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: qsar_fish_toxicity%2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: servo%4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slice_localization_data%value146.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slice_localization_data%value335.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slice_localization_data%value339.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slice_localization_data%value359.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slice_localization_data%value361.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: slump_test%SLUMP(cm).csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: stock portfolio performance data set%Annual Return.1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: stock portfolio performance data set%Total Risk.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-mat%G1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-mat%G2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-mat%G3.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-por%G1.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-por%G2.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: student-por%G3.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: superconduct_train%mean_Density.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: superconduct_train%wtd_entropy_ThermalConductivity.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: superconduct_train%wtd_entropy_atomic_radius.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: superconduct_train%wtd_std_atomic_radius.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: superconduct_train%wtd_std_fie.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: ticdata2000%0.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: transcoding_mesurment%duration.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: transcoding_mesurment%utime.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wdbc%14.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wdbc%17.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wdbc%29.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wheat_200910-201803%open.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: winequality-red%free sulfur dioxide.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: winequality-white%citric acid.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wpbc%13.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wpbc%16.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wpbc%17.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: wpbc%19.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n",
      "proccessing file: yacht_hydrodynamics%4.csv\n",
      "method: drop\n",
      "method: mean\n",
      "method: median\n"
     ]
    }
   ],
   "source": [
    "#This creates and processes the tree to get the metafatures. The metafeature vector is saved in\n",
    "#a txt file located in \"../DATAsets/DATA/tree_metafeatures_for_test_CSVs\" dir.\n",
    "datasets = os.listdir(target_test_path)\n",
    "extra_ignore = ['COMBO17%e.W462FE.csv', 'SkillCraft1_Dataset%WorkersMade.csv'] #These two only have 1 node in their trees, the root.\n",
    "for file in np.sort(np.setdiff1d(datasets, extra_ignore, assume_unique=True)):\n",
    "    print('proccessing file: ' + file)\n",
    "    for method in ['drop','mean','median']:\n",
    "        if not os.path.isfile(tree_meta_feature_path + '/' + method + '/' + file):\n",
    "            print('method: ' + method)\n",
    "            df = pd.read_table(target_test_path + '/'+ file,sep=',')\n",
    "            df, MNpL = tree_ready(df, method)\n",
    "\n",
    "            with open(tree_meta_feature_path + '/' + method + '/' + file,'w' ) as f:\n",
    "                for i,x in enumerate(metafeatures(df)):\n",
    "                    f.write(str(x)+',')\n",
    "                f.write(str(MNpL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
